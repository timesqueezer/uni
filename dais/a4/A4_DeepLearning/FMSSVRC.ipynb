{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df5bbb9",
   "metadata": {},
   "source": [
    "# 4 FMSSVRC\n",
    "__Fashion-MNIST Small Scale Visual Recognition Challenge__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96c3b51",
   "metadata": {},
   "source": [
    "We want to write a powerful model that can make accurate predictions and correctly classify different pieces of clothing.\n",
    "\n",
    "Most of the code is already written, including a deep neural network model.\n",
    "However, the performance of said model is subpar. It is your task to complete indicated functions and cells, so that you can train the model. Further, you should change and tweak the model as well as hyperparameters to create a well performing model. You can aim for accuracies in the high 80ies!\n",
    "\n",
    "Experiment around with architecture choices and different hyperparamters. The lecture slides and PyTorch give you a good overview of what is possible. Keep in mind, though, that blindly copy-pasting code from other sources without proper referencing and consent can be seen as plagiarism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9b0f04",
   "metadata": {},
   "source": [
    "The quality of your model is evaluated on the test data set. Continously optimising your model according to the performance on the test data set is bad scientific practice. Ideally, the evaluation on the test data should happen  just once, when you are confident that you have trained your model to the best of your knowledge. While tweaking your model, you may evaluate its quality on a validation set of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbde7102",
   "metadata": {},
   "source": [
    "You are not allowed to change arbitrary code of the notebook. Instead, functions, variables etc. which you can change, will be indicated explicitely (see __Task__ keyword).\n",
    "Please leave the seeds intact!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ffe4d0",
   "metadata": {},
   "source": [
    "## 4.1 Installing PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e699a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.8.1-cp39-cp39-manylinux1_x86_64.whl (804.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 804.1 MB 21 kB/s  eta 0:00:010\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.9.1-cp39-cp39-manylinux1_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3 MB 8.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions\n",
      "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: numpy in /mnt/super_raid/uni/dais/env/lib/python3.9/site-packages (from torch) (1.20.3)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /mnt/super_raid/uni/dais/env/lib/python3.9/site-packages (from torchvision) (8.2.0)\n",
      "Installing collected packages: typing-extensions, torch, torchvision\n",
      "Successfully installed torch-1.8.1 torchvision-0.9.1 typing-extensions-3.10.0.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/mnt/super_raid/uni/dais/env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7390d495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "torch.manual_seed(42)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e8d6f1",
   "metadata": {},
   "source": [
    "## 4.2 Obtaining the dataset\n",
    "We are going to use the [Fashion-MNIST](https://arxiv.org/abs/1708.07747) dataset, which is a more difficult alternative to the standard MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f466806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "31.3%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "51.0%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "70.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "90.4%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.6%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8.8%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60.4%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if, for some reason, you are not using a UNIX-based operating system, \\\n",
    "# you might need to adjust the path arguments\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=torchvision.transforms.ToTensor())\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=torchvision.transforms.ToTensor())\n",
    "label_names = {0:\"T-shirt/top\", 1:\"Trouser\", 2:\"Pullover\", 3:\"Dress\",\n",
    "               4:\"Coat\", 5:\"Sandal\", 6:\"Shirt\", 7:\"Sneaker\", 8:\"Bag\", \n",
    "               9:\"Ankle boot\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ebe17",
   "metadata": {},
   "source": [
    "### Task 4.2.1 Inspecting a sample from the data\n",
    "Choose a random sample from the training data, and:\n",
    "- print its shape\n",
    "- visualise the sample with an appropriate plot\n",
    "- print its label (or title the plot appropriately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94ef3006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample inspection here\n",
    "import matplotlib.pyplot as plt\n",
    "print(trainset[0][0].shape)\n",
    "plt.imshow(trainset[0][0].permute(1, 2, 0), cmap='gray')\n",
    "print(trainset[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0786fb6",
   "metadata": {},
   "source": [
    "### Task 4.2.2 Validation Split \n",
    "\n",
    "__YOU MAY EDIT PARTS OF THE NEXT CELL__\n",
    "\n",
    "In order to judge the quality of your training efforts, you might want to validate your model on a part of the data it has not seen yet. However, we cannot do that repeatedly on the test data set.\n",
    "\n",
    "Therefore, we can split off some data from our training data. Make a decision about the validation split! The more data you take off from the training set, the more accurate will your evaluation be. The less data you leave for actual training, the worse your model performance will be.\n",
    "\n",
    "_Hint:_ Currently, the validation size is 100, which seems a bit small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "779e8770",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 500 # set the size of your validation set\n",
    "trainset, valset = torch.utils.data.random_split(trainset, \n",
    "                                                 [len(trainset)-validation_size, validation_size], \n",
    "                                                 generator=torch.Generator().manual_seed(1337))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ad869",
   "metadata": {},
   "source": [
    "### 4.2.3 Torch DataLoader\n",
    "Now we can hand over our three datasets to the DataLoader class which brings a lot of convience to the training procedure. It can batch and shuffle our data.\n",
    "\n",
    "The batch size is set to 32 which is an appropriate value. You may change the batch_size for the trainloader, if you want.\n",
    "\n",
    "Shuffling is not needed for validation and testing because we are only running through the data once, anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bfbc794",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=32,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fcdffa",
   "metadata": {},
   "source": [
    "## Task 4.3 Building a Model with torch.nn.Sequential\n",
    "__YOU MAY EDIT PARTS OF THE NEXT CELL__\n",
    "\n",
    "We are going to use [torch.nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) to build a multi-layer perceptron (not a CNN!).\n",
    "You can simply supply [layers and building blocks](https://pytorch.org/docs/stable/nn.html) as arguments to create your network architecture in a sequential way, i.e. the data will flow through the network in the order they are listed as arguments.\n",
    "\n",
    "Useful modules for MLPs are:\n",
    "- [Linear Layers](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
    "- [Activation Functions](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
    "- [Dropout Layers](https://pytorch.org/docs/stable/nn.html#dropout-layers)\n",
    "\n",
    "The input to the model is an image, which has to be flattened to a vector, so that it is represented as suitable input for the MLP.\n",
    "\n",
    "The output must be a vector of size 10 (according to our labels/classes).\n",
    "\n",
    "You are supplied with a model that does not perform too well. You are free to build a MLP of your choosing. Be aware, that larger networks will take more time to train!\n",
    "\n",
    "Tips for experimentation:\n",
    "- Layer sizes\n",
    "- Number of layers\n",
    "- Activation functions\n",
    "- Dropout\n",
    "\n",
    "_Hint:_ What is known in PyTorch as a linear layer refers to a fully connected or dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42cd8e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Flatten(),\n",
    "                      nn.Linear(28*28, 2000),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.2),\n",
    "                      nn.Linear(2000, 1000),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.2),\n",
    "                      nn.Linear(1000, 500),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.2),\n",
    "                      nn.Linear(500, 200),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(200, 10),\n",
    "                      nn.Softmax()\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78380467",
   "metadata": {},
   "source": [
    "## 4.4 Training the model\n",
    "Now that we have a model architecture, we will need to specify a training procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c9a2b8",
   "metadata": {},
   "source": [
    "### Task 4.4.1 Choosing hyperparameters\n",
    "__YOU MAY EDIT PARTS OF THE NEXT CELL__\n",
    "\n",
    "A few parameters for the training process need to be predefined and are not learned via gradient descent or backprop. We refere to these as hyperparameters.\n",
    "\n",
    "In the following, you are presented with four of those that shape the training process and can have great influence on the trained models performance.\n",
    "\n",
    "The machine-learning practictioner who set up this notebook apparently did not pay full attention to the lecture and literature. Although all lead to a working model, the values of some are not chosen to the best of our knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8969c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddea12df",
   "metadata": {},
   "source": [
    "### 4.4.2 The train function\n",
    "This function trains your model for one epoch and keeps track of the correct/incorrect predictions.\n",
    "\n",
    "It takes a model, a dataloader, and optimizer and a loss function, trains the model for one epoch and returns the mean loss over the epoch as well as the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b84f817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for img, lbl in dataloader:\n",
    "        optimizer.zero_grad() \n",
    "        out = model(img) \n",
    "        logits, indices = torch.max(out, 1)\n",
    "        correct += torch.sum(indices == lbl).item()\n",
    "        total += len(lbl)\n",
    "        batch_loss = loss(out, lbl) \n",
    "        batch_loss.backward() \n",
    "        optimizer.step() \n",
    "        epoch_loss.append(batch_loss.item()) \n",
    "    return np.mean(epoch_loss), correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca68321",
   "metadata": {},
   "source": [
    "### 4.4.3 The validation function\n",
    "This function evaluations your model on specified data.\n",
    "\n",
    "It takes a model and a dataloader and returns the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01c879d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for img, lbl in dataloader:\n",
    "        out = model(img)\n",
    "        logits, indices = torch.max(out, 1)\n",
    "        correct += torch.sum(indices == lbl).item()\n",
    "        total += len(lbl)\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2c6b9",
   "metadata": {},
   "source": [
    "### Task 4.4.4 The training loop\n",
    "Write the training loop for your model:\n",
    "- Call the train function for your model for the specified number of epochs. \n",
    "- For each epoch, keep track of the loss and the training accuracy.\n",
    "- You should also keep track of the validation accuracy, to judge the models actual performance on unseen data.\n",
    "- Store all values for visualisation purposes later on.\n",
    "\n",
    "Run your training loop! Depending on the size of your network architecture and the number of epochs, this might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "706fa46e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/super_raid/uni/dais/env/lib/python3.9/site-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainings-loss:  2.3021224434657763\n",
      "training-acc:  0.10020168067226891\n",
      "valacc 0.076\n",
      "trainings-loss:  2.3007058475607183\n",
      "training-acc:  0.10164705882352941\n",
      "valacc 0.082\n",
      "trainings-loss:  2.2961514831871113\n",
      "training-acc:  0.14746218487394958\n",
      "valacc 0.228\n",
      "trainings-loss:  2.251135077399592\n",
      "training-acc:  0.25142857142857145\n",
      "valacc 0.276\n",
      "trainings-loss:  2.0267436515900394\n",
      "training-acc:  0.4664201680672269\n",
      "valacc 0.618\n",
      "trainings-loss:  1.8231829731054203\n",
      "training-acc:  0.662016806722689\n",
      "valacc 0.754\n",
      "trainings-loss:  1.7592098191861183\n",
      "training-acc:  0.724890756302521\n",
      "valacc 0.788\n",
      "trainings-loss:  1.729003620404069\n",
      "training-acc:  0.7454453781512606\n",
      "valacc 0.772\n",
      "trainings-loss:  1.7125741550999303\n",
      "training-acc:  0.7572268907563026\n",
      "valacc 0.796\n",
      "trainings-loss:  1.6993244929339295\n",
      "training-acc:  0.7694453781512605\n",
      "valacc 0.804\n"
     ]
    }
   ],
   "source": [
    "# training loop here\n",
    "lossarr = []\n",
    "accarr = []\n",
    "valaccarr = []\n",
    "for i in range(epochs):\n",
    "    trloss,tracc = train(model, trainloader, optimizer, loss)\n",
    "    valacc = evaluate(model, valloader)\n",
    "    lossarr.append(trloss)\n",
    "    accarr.append(tracc)\n",
    "    valaccarr.append(valacc)\n",
    "    print(\"trainings-loss: \", trloss)\n",
    "    print(\"training-acc: \", tracc)\n",
    "    print(\"valacc\", valacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a130c63",
   "metadata": {},
   "source": [
    "### Task 4.4.5 Visualise the training\n",
    "Visually inspecting the models behaviour over the training period can give insights on problems and performance issues.\n",
    "\n",
    "Plot:\n",
    "- the training loss and the training accuracy\n",
    "- the validation accuracy\n",
    "\n",
    "over the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81d29a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "epochs = np.arange(len(lossarr))\n",
    "plt.scatter(epochs, lossarr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b02f989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot acc\n",
    "epochs = np.arange(len(valaccarr))\n",
    "plt.scatter(epochs, valaccarr)\n",
    "plt.scatter(epochs, accarr, c='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b95b0",
   "metadata": {},
   "source": [
    "## 4.5 Testing your model\n",
    "The following should only be executed once. If you are not satisfied with your model performance, go back a few steps and tune your model with different parameters or change the model architecture.\n",
    "\n",
    "If you are checking your model's performance on the test set and then tune it for better performance, you are essentially fitting your model to the test set. Your actual generalization capabilities will decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27b6f224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model correctly classified 77.58 % of all samples.\n"
     ]
    }
   ],
   "source": [
    "test_acc = evaluate(model, testloader)\n",
    "print(\"Your model correctly classified\", round(test_acc*100,2), \n",
    "      \"% of all samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebfb140",
   "metadata": {},
   "source": [
    "### Task 4.5.1 Prediction capabilities of the model\n",
    "Although we now know the average prediction performance of the model on unseen data, not all data is as equally distributed as our training data. Some classes can be harder to predict, than others.\n",
    "\n",
    "Analyse your models performance on the different classes and plot the prediction accuracies on the test set over the 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "692b38b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-2739c7e154e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# plot acc for classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdataset_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdataset_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_full' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4fe6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
