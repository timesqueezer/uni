%!TEX encoding = UTF-8 Unicode
% ================================================================================
\documentclass[
    fontsize=12pt,
    headings=small,
    parskip=half,           % Ersetzt manuelles Setzen von parskip/parindent.
    bibliography=totoc,
    numbers=noenddot,       % Entfernt den letzten Punkt der Kapitelnummern.
    open=any,               % Kapitel kann auf jeder Seite beginnen.
    final                   % Entfernt alle todonotes und den Entwurfstempel.
    ]{scrreprt}
% ===================================Praeambel==================================
\include{stylesvs}

\addbibresource{expose.bib}

% ===================================Dokument===================================

\title{How well can federated learning be utilized to implement a decentralized and privacy focused bot detection system for websites?}
\author{Matz-Jona Radloff}
% \date{01.01.2015} % Falls ein bestimmtes Datum eingesetzt werden soll, einfach
                    %  diese Zeile aktivieren.

\begin{document}

\begin{titlepage}
\begin{center}\Large
	\vfill
    Expos√© for Bachelor Thesis
	\vfill
	\makeatletter
	{\Large\textsf{\textbf{\@title}}\par}
	\makeatother
	\vfill
    submitted by
	\par\bigskip
	\makeatletter
	{\@author} \par
	\makeatother
	Matriculation number 6946325 \par
	Study Program: Computer Science
	\vfill
	\makeatletter
	submitted on {\@date}
	\makeatother
	\vfill
	Supervisor: August See\par
	First reviewer: Prof. Dr. Mathias Fischer \par
	Zweitgutachter: N.N.
\end{center}
\end{titlepage}


\chapter*{Abstract}

Malicious use of automated bots present an increasing risk to applications in the web. Existing solutions do either not perform well, are not accessible to many providers due to high cost, or disregard modern privacy standards. This work aims to provide a proof-of-concept for a basic system that incorporates all of the above criterions.

Option 1:
These concerns will be addressed by implementing an open-source library that uses federated learning and its performance will be compared against existing solutions.

Option 2:
The usage of federated learning which allows the usage of additional user data will be compared against a non-federated approach and different input data.

\tableofcontents

\chapter{Motivation}

In this work, the term bot is referring to software that is automatically performing HTTP(S) requests with the intent of harming the target or reaching another malicous goal. While this threat is nothing new to the web the attack surface has grown significantly over the past year \cite{BAD_BOT_REPORT2020} \cite{BAD_BOT_REPORT2021}. Especially the increased usage of web interfaces in poorly secured IoT devices and the trend to (re-)implement software as web applications is responsible for this.

The usage of bots can have several goals. DoS attacks aim to overload the target's infrastructure such that it becomes inaccessible for normal use. Carding and Credential stuffing refers to performing payment or login requests to find working credit card numbers and credentials usually obtainend from a data breach. Data scrapers download the website data and can use the data for malicious purposes, e.g. damage SEO or violate copyrights. Content spam includes inserting malicious or polluting data on platforms that allow user generated content. Scalping or inventory hoarding of shopping items can artificially raise prices, damage brands, generate false market forces and create a bad customer experience.

Recent studies show that of 2020's internet traffic 25.6\% was fraudulent and automatically generated \cite{BAD_BOT_REPORT2020} \cite{BAD_BOT_REPORT2021}. They also show that both the percentage of bot traffic in general as well as malicious bot traffic has increased over time.

Most of the above attacks need to trick the webserver and application backends into performing the request as if it had been initiated by a human. Instead of combating the resulting issues separately, bot detection could potentially mitigate many at once.

A complication in this problem space is the, often desired, requirement for non-malicious bots to be granted normal access. The most prominent example are scraper bots from search engines that need to request websites periodically to build their search indices. A common technique to exploit this requirement is trying to emulate known bot signatures from large search engines, e.g. Googlebot \cite{8421894}.

Many website operators tend to use solutions that are easy to integrate. This requires embeding external software which collects user data and sends it to servers of the software vendors. Closed source software does not allow to determine what exactly happens to the user data and website operators open themselves to additional threats in case of a data breach. Depending on the operating countries of both the websites and software vendors, data privacy regulation might also not allow sharing user data at all or require the operator to document the concrete data transfer in a very detailed and legally complicated way, e.g. in countries falling under the GDPR \cite{GDPR}. Because of the above reasons it is desirable to either employ self-hosted software or use a solution that does not require user data transfers.

\todo{machine learning motivation}

A promising technique that combines both machine learning and respects modern privacy standards is federated learning \cite{DBLP:journals/corr/KonecnyMR15} \cite{DBLP:journals/corr/KonecnyMRR16}.


\chapter{Related Work}

\section{Proprietary Solutions}

\url{https://datadome.co/} \\
\url{https://www.perimeterx.com/products/bot-defender/} \\
\url{https://www.imperva.com/products/advanced-bot-protection-management/} \\
\url{https://www.fastly.com/products/cloud-security/bot-protection} \\
\url{https://www.cloudflare.com/products/bot-management/} \\
\url{https://developers.google.com/recaptcha/docs/v3} \\
\url{https://www.hcaptcha.com/} \\


\section{Scientific Work}

The paper \cite{LiJi2021} introduces a federated learning approach similar to the goals of this work but differs in the specific use case and implementation. Their system focuses on the detection of IoT (Internet of Things) devices which are easily hacked and turned into zombies. These zombies are commonly used in DDoS (Distributed Denial of Service) attacks which their strategy tries to make not feasible to perform. They also develop their own iterative model averaging based method "gated recurrent unit" (GRU) which is optimized for their specific use case.

\todo{More sources}

Many of the above solutions use the actual IP network traffic to extract relevant information to be used as input parameters for their models and are intended to be run in a server environment. In comparison clients' browser environments in the web offer a much greater amount and variety of user information that might be very useful to differentiate between a valid user and a malicious bot.

The work of \cite{PETS2021} outlines the problems and privacy-realted concerns really well and tries to solve a very similar problem but focuses on mobile devices. The authors run a pre-trained machine learning model on the user's device. To avoid local changes to the model a cryptographic proof is generated that is verified on a server.

Among others, the works of Shen et al. \cite{6263955} and Antal et al. \cite{9111596} \cite{DBLP:journals/corr/abs-1810-04668} show the viability of using mouse and trackpad actions to verify the authenticity of users but privacy concerns often stand in the way of using such a method in practice.

Additionally Acien et al. \cite{Acien2020BeCAPTCHAMouseSM} show the feasibility of using biometric features for bot detection in general and propose new mouse trajectory synthesis methods as well as a GAN-based learning system that can distinguish between humans and bots with 93\% accuracy with only one mouse trajectory as input.


\chapter{Method}

\section{Concept}

The thesis hypothesizes that machine learning systems incorporating federated learning perform better than non-federated counterparts while maintaining user privacy. It assumes that users perform actions on websites using a mouse or touchpad which are hard to fake by attackers trying to emulate human behavior. Raw mouse data is segmented into mouse actions such as mouse move (MM) or mouse move and a click (point and click, PC) similar to \cite{9111596} and their previous paper \cite{DBLP:journals/corr/abs-1810-04668}. Multiple results can be averaged to increase detection performance.

\section{Datasets}

Many publicly available datasets exist that contain valid user mouse movement and click data. The following datasets will be aggregated and labeled as human input.
Shen et al.'s \cite{6263955} dataset contains mouse dynamics information from 28 users and 30 sessions per users which each contain around 3000 mouse events.
The DFL dataset \cite{9111596} includes 20-30 sessions of 21 users.
The Balabit Mouse Dynamics Challenge Data Set \cite{BALABIT_CHALLENGE} includes a few longer session and several shorter session which are meant to be used for training and testing respectively. For the purposes of bot detection, both can be used.

If needed, additional datasets are available, e.g.:

\url{https://figshare.com/articles/dataset/Mouse_Behavior_Data_for_Static_Authentication/5619313}

\url{https://www.uvic.ca/ecs/ece/isot/datasets/?utm_medium=redirect&utm_source=/engineering/ece/isot/datasets/&utm_campaign=redirect-usage#section0-3}

Data labeled as bot input will be generated using three methods. The first naive approach interpolates linearly between the start and end point of randomly generated movements. The second method adds noise and the third uses both B-spline interpolation and noise. More complicated simulations exist but their implementations are not publicly available. \cite{8275816} \cite{Nazar2003} The three methods used depict a reasonable choice of a basic attack that tries to evade detection by fake mouse movement.


A percentage of the aggregated data will be split and used as test data while the rest is used for training.


\section{Machine Learning Model}

Many different machine learning models are suitable for binary classification. Hu et al. \cite{8275816} compare different classifiers in a similar context with Random Forest and Multilayer Perceptron performing the best. If time allows it, the thesis will compare multiple classification methods against each other and only use one otherwise.

The input features will consist of the (probably normalized) $x$- and $y$-coordinates as well as a time value for each mouse event. Additional features will be engineered similar to \cite{DBLP:journals/corr/abs-1810-04668}, such as mean, standard deviation, minimum and maximum value of path tangent, horizontal, vertical and overall velocity, acceleration, jerk, angular velocity. Additionally the type of action, length of the movement and time needed to complete the action will be used.

A system for pre-processing the different datasets will be developed.

The thesis will use Tensorflow with and without federated learning with a Random Forest keras model. Tensorflow is one of the most widely used machine learning frameworks and the integration of its runtime into distributed learners in the form of website backends or even client devices is feasible. The thesis will not include the actual integration into such systems. A simulated environment of multiple Tensorflow instances that have access to a secure communications channel will be developed.

\section{Evaluation}

The bot datasets will be split by their generation method such that different combinations of data are used per learning participant. The human datasets will also be split into subsets containing random samples from all or only specific datasets. The thesis will primarily compare the performance of the individual classifiers with and without federated learning with the hypothesis that the more learning results of different input data is combined, the better the overall performance.

\chapter{Time plan}

My planned steps in roughly two week intervals: \\

\begin{enumerate}
	\item Start implementing data aggregator and feature extractor
	\item Extract features of one dataset
	\item Implement bot data generator (only naive type)
	\item Build the Tensorflow model, verify that it works and that it can classify the data correctly
	\item Integrate Federated learning and build the simulated environment of multiple distributed learners
	\item Aggregate the remaining datasets and extend the bot data generation
	\item Formulate and perform the experiments to test the thesis' hypothesis
	\item Process and visualize the results
\end{enumerate}

\iffalse % old

\chapter{Proposed Architecture}

This work aims to incorporate an existing library that provides federated learning capabilities and can be run either on the client's browser or the websites' servers. Ideally an existing machine learning will be used to limit the scope of the thesis.

The proof of concept is intended to show the feasibility of implementing such a system while taking the specified constraints into account. It will include multiple website instances that all use the bot detection library and a primary server that holds the model, facilitates communication to and from the website instances, and incorporates learned updates.

To avoid having to use user data at all, the learning system could only work on request metadata on the web server or backend level. In this case the available data would be limited to combinations of IP data, such as addresses and timing data, as well as HTTP request metadata which, in most cases, contains pre-defined data that can be easily faked by bots. As \cite{PETS2021} shows, having access to user data from the client's device can be very successful so this work assumes that dynamic user data is needed in order to properly distinguish between human- and bot-initiated requests. It also needs to determine whether it suffices to gather data in the website's backend or frontend only or if both sources are needed. For now all possiblities will remain open and potential existing software will be evaluated.

At the same time a friction-less system is desired that uses already existing data instead of requiring additional user input, e.g. solving a puzzle or performing object detection.

\section{Website Instance Structure}

The thesis will be using the Flower framework because it can use several different machine learning backends for greater flexibility in the choice of network used. It will run as part of the server implementation of the respective websites.

To be determined is whether to perform the actual training of the model in the client's browser or the websites' backend server. The former variant has the advantage of the client data never leaving the own browser which makes a strong case for privacy concerns. It also allows websites that don't use or don't have access to a backend to use this system. Its disadvantages are potentially high performance penalties, e.g. if the training code needs to run on older hardware which also might affect the actual website's performance. Another potential risk is the exposure of the training logic and model which attackers might use to reverse engineer the system and find a way to disguise themselves as non-malicious clients.

Analysis of available libraries revealed only three potential candidates for the browser-based approach:

\begin{enumerate}
	\item Experimental and unmaintained library for TensorFlow.js \cite{PAIRFL2019}
	\item A github user's attempt \cite{SaFL2019} to solve this problem following a discussion in TensorFlow's github issues.
	\item Implementing an own solution on top of a browser-based ML library.
\end{enumerate}

The amount and quality of libraries suitable for the server-side approach seems to be much higher. A selection of the most popular libraries includes the following projects:

\begin{enumerate}
	\item \url{https://github.com/IBM/federated-learning-lib}
	\item \url{https://fedml.ai/}
	\item \url{https://flower.dev/}
	\item \url{https://www.tensorflow.org/federated/federated_learning}
\end{enumerate}

Weighing the advantages and disadvantages of both solutions against each other leads to the choice of running the federated learning client on the website's backends. Both the potentially increased performance and non-exposure of the learning logic and model are the biggest factors in this choice. Privacy-concious website operators need to either choose a hoster that provides access to the backend software, or host the application backend themselves such that control over the user data can be guaranteed. Due to this the requirement to install the software in the backend is reasonable.

\section{Backend Technology Stack}

As python is the de-facto language of choice for machine learning applications and has both great available projects for web applications and is well suitable for rapid prototyping, it is also used for both the website instances' and primary server's backends.

The specific software stack consists of a python application using the Flask microframework which serves a REST-style API and the static frontend files in the website instances.


\section{Federated Learning}

A big part of the system design is going to be the choice of user data and transformations performed on the same to be used in the model's parameter space.


\chapter{Empirical Study}

\section{Performance}

To be determined is whether the proposed architecture actually works with the goal.

\fi


\begin{raggedright}
  \printbibliography
\end{raggedright}

\end{document}
